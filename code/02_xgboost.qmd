---
title: "Data Science Applied to Ag - Final Project - ML"
format:
  html:
    embed-resources: true
    toc: true
    theme: cerulean
author: Md Shakir Moazzem, Umar Munir
---

# Introduction

This script contains ML Workflow with XGBoost

## Loading libraries

The following code chunk will load necessary packages.

```{r}
#| message: false
#| warning: false

#install.packages("tidymodels")   # Core framework for modeling (includes recipes, workflows, parsnip, etc.)
#install.packages("finetune")     # Additional tuning strategies (e.g., racing, ANOVA-based tuning)
#install.packages("vip")          # For plotting variable importance from fitted models
#install.packages("xgboost")      # XGBoost implementation in R
#install.packages("ranger")       # Fast implementation of Random Forests
#install.packages("tidyverse")    # Data wrangling and visualization
#install.packages("doParallel")   # For parallel computing (useful during resampling/tuning)
#install.packages("caret")  
#install.packages("xgboost") #new pacakage
#install.packages("caret")

library(tidymodels)   # Core framework for modeling (includes recipes, workflows, parsnip, etc.)
library(finetune)     # Additional tuning strategies (e.g., racing, ANOVA-based tuning)
library(vip)          # For plotting variable importance from fitted models
library(xgboost)      # XGBoost implementation in R
library(ranger)       # Fast implementation of Random Forests
library(tidyverse)    # Data wrangling and visualization
library(doParallel)   # For parallel computing (useful during resampling/tuning)
library(caret)       # Other great library for Machine Learning 
```

## Loading the data set

The following code chunk will load the "weather_monthsum.csv" data set.

```{r weather}

weather <- read_csv("../data/weather_monthsum.csv")

weather

```

# ML workflow

## 1. Pre-processing

### a. Data split

The following code chunks will conduct data split (70% training / 30% testing).

```{r weather_split}

set.seed(931735) # Setting seed to get reproducible results 

weather_split <- initial_split(
  weather, 
  prop = .7, # proption of split same as previous codes
  strata = yield  # Stratify by target variable
  )

weather_split

```

The following code chunk will conduct setting train set.

```{r weather_train}

weather_train <- training(weather_split)  # 70% of data

weather_train #This is your traing data frame

```

The following code chunk will conduct setting test split.


```{r weather_test}

weather_test <- testing(weather_split)    # 30% of data

weather_test

```

### b. Distribution of target variable "yield"

The following code chunk will create a density plot to compare target variable "yield" in the training and test set.

```{r distribution}

ggplot() +
  geom_density(data = weather_train, 
               aes(x = yield),
               color = "red") +
  geom_density(data = weather_test, 
               aes(x = yield),
               color = "blue") 
  

```

### c. Data processing with recipe

The following code chunk will conduct data processing with recipe.

```{r weather_recipe}

# Create recipe for data preprocessing
weather_recipe <- recipe(yield ~ ., data = weather_train) %>% 
  # Remove identifier columns and months not in growing season
  step_rm(
    year,       # Remove year identifier
    site,       # Remove site identifier
    hybrid,     # Remove site identifier
    matches("Jan|Feb|Mar|Dec")  # Remove non-growing season months
  ) 


weather_recipe

```

The following code chunk will prep the recipe to estimate any required statistics.

```{r weather_prep}
# Prep the recipe to estimate any required statistics
weather_prep <- weather_recipe %>% 
  prep()

# Examine preprocessing steps
weather_prep
```

## 2. Training

### a. Model specification

The following code chunk will fine tune the "trees", "tree_depth", "min_n", and "learn_rate" XgBoost hyperparameters.

```{r xgb_spec}

xgb_spec <- boost_tree(
  trees = tune(),
  tree_depth = tune(),  # Maximum depth of each tree
  min_n = tune(),  # Minimum samples required to split a node
  learn_rate = tune()
  ) %>% #Specifying XgBoost as our model type, asking to tune the hyperparameters
  set_engine("xgboost") %>% #specify engine 
  set_mode("regression")  # Set to mode
      
xgb_spec

```

### b. Cross-validation setup

The following code chunk will conduct 5-fold cross-validation to evaluate model performance during tuning.

```{r}

set.seed(235) #34549

resampling_foldcv <- vfold_cv(weather_train, 
                              v = 5)

resampling_foldcv

resampling_foldcv$splits[[1]]

```

### c. Hyperparameter grid with Latin Hypercube Sampling

The following code chunk will use Latin hypercube sampling to generate a diverse grid of hyperparameter combinations.

```{r }

xgb_grid <- grid_latin_hypercube(
  trees(),
  tree_depth(),
  min_n(),
  learn_rate(),
  size = 20
)

xgb_grid

```

The following code chunk will plot the hyperparameter combinations.

```{r}
ggplot(data = xgb_grid,
       aes(x = tree_depth, 
           y = min_n)) +
  geom_point(aes(color = factor(learn_rate), #coloring the bubbles based on learn_rate
                 size = trees), #size of the bubbles are based on the tress
             alpha = .5,
             show.legend = FALSE)
```

## 3. Model Tuning

The following code chunk will conduct model tuning.

```{r xgb_grid_result}

#install.packages("doParallel")
#install.packages("parallel")

library(doParallel)
library(parallel)

set.seed(76544)

#parallel processing
#registerDoParallel(cores = parallel::detectCores()-1) #starts parallel processing

xgb_res <- tune_race_anova(object = xgb_spec,
                      preprocessor = weather_recipe,
                      resamples = resampling_foldcv,
                      grid = xgb_grid,
                      control = control_race(save_pred = TRUE))

#stopImplicitCluster() #ends parallel processing

beepr::beep()

xgb_res$.metrics[[2]]

```

## 4. Select Best Models

We select the best models using three strategies (lowest RMSE, highest R2, within 1 SE, within 2% loss).

The following code chunk will select best model based on lowest RMSE.

```{r}

# Based on lowest RMSE
best_rmse <- xgb_res %>% 
  select_best(metric = "rmse")%>% 
  mutate(source = "best_rmse")

best_rmse

```

The following code chunk will select best model based on lowest RMSE within 1% loss

```{r}
# Based on lowest RMSE within 1% loss
best_rmse_pct_loss <- xgb_res %>% 
  select_by_pct_loss("min_n",
                     metric = "rmse",
                     limit = 1
                     )%>% 
  mutate(source = "best_rmse_pct_loss")

best_rmse_pct_loss
```

The following code chunk will select best model based on lowest RMSE within 1 SE.

```{r}
# Based on lowest RMSE within 1 se
best_rmse_one_std_err <- xgb_res %>% 
  select_by_one_std_err(metric = "rmse",
                        eval_time = 100,
                        trees
                        )%>% 
  mutate(source = "best_rmse_one_std_err")

best_rmse_one_std_err
```

The following code chunk will select best model based on greatest R2.

```{r}
# Based on greatest R2
best_r2 <- xgb_res %>% 
  select_best(metric = "rsq")%>% 
  mutate(source = "best_r2")

best_r2
```

The following code chunk will select best model based on greatest R2 within 1% loss.

```{r}
# Based on greatest R2 within 1% loss
best_r2_pct_loss <- xgb_res %>% 
  select_by_pct_loss("min_n",
                     metric = "rsq",
                     limit = 1
                     ) %>% 
  mutate(source = "best_r2_pct_loss")

best_r2_pct_loss
```

The following code chunk will select best model based on greatest R2 within 1 SE

```{r}
# Based on greatest R2 within 1 se
best_r2_one_std_error <- xgb_res %>% 
  select_by_one_std_err(metric = "rsq",
                        eval_time = 100,
                        trees
                        ) %>%
  mutate(source = "best_r2_one_std_error")

best_r2_one_std_error
```

## Compare and Finalize Model

The following code chunk will compare all models

```{r comparing values}
best_rmse %>% 
  bind_rows(best_rmse_pct_loss, 
            best_rmse_one_std_err, 
            best_r2, 
            best_r2_pct_loss, 
            best_r2_one_std_error)
```

## 5. Final Specification

The following code chunk will conduct final specification.

```{r final_spec_fit}
final_spec <- boost_tree(
  trees = best_r2$trees,           # Number of boosting rounds (trees)
  tree_depth = best_r2$tree_depth, # Maximum depth of each tree
  min_n = best_r2$min_n,           # Minimum number of samples to split a node
  learn_rate = best_r2$learn_rate  # Learning rate (step size shrinkage)
) %>%
  set_engine("xgboost") %>%
  set_mode("regression")

final_spec
```

## 6. Final Fit and Predictions

## Validation

The following code chunk will conduct the final fit and collect predictions on the final fit.

```{r final_fit}
set.seed(10)
final_fit <- last_fit(final_spec,
                weather_recipe,
                split = weather_split)

final_fit %>%
  collect_predictions()
```

## 7. Evaluate on *Test Set*

The following code chunk will evaluate fit metrics on the test set.

```{r final_fit_metrics}
final_fit %>%
  collect_metrics()
```

## 8. Evaluate on Training Set

The following code chunk will evaluate fit metrics on the training set.

```{r}
final_spec %>%
  fit(yield ~ .,
      data = bake(weather_prep, 
                  weather_train)) %>%
  augment(new_data = bake(weather_prep, 
                          weather_train)) %>% 
  rmse(yield, .pred) %>%
  bind_rows(
    
    
# R2
final_spec %>%
  fit(yield ~ .,
      data = bake(weather_prep, 
                  weather_train)) %>%
  augment(new_data = bake(weather_prep, 
                          weather_train)) %>% 
  rsq(yield, .pred))
```

## 9. Predicted vs Observed Plot

The following code chunk will create a Predicted vs Observed Plot.

```{r}
final_fit %>%
  collect_predictions() %>%
  ggplot(aes(x = yield,
             y = .pred)) +
  geom_point() +
  geom_abline() +
  geom_smooth(method = "lm") +
  scale_x_continuous() +
  scale_y_continuous() 
```

## 10. Variable Importance

The following code chunk will create a Variable Importance plot.

```{r final_spec}
final_spec %>%
  fit(yield ~ .,
         data = bake(weather_prep, weather_train)) %>% #There little change in variable improtance if you use full dataset
    vi() %>%
  mutate(
    Variable = fct_reorder(Variable, 
                           Importance)
  ) %>%
  ggplot(aes(x = Importance, 
             y = Variable)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)
```


# Obtaining "yield" prediction on the "testing_submission.csv" data set

[Note: before using it, make sure that the code below actually works]

```{r}

# Reading & cleaning testing data 

submission   <- read_csv("../data/testing/testing_submission.csv") %>% 
  mutate(site = str_remove_all(site, "[a-z]"),
         site = str_replace(site, "-.*$", ""),
         site = str_replace(site, "_.*$", ""))

meta_test    <- read_csv("../data/testing/testing_meta.csv")  %>% 
  rename(lon = longitude, lat = latitude) %>% 
  mutate(site = str_remove_all(site, "[a-z]"),
         site = str_replace(site, "-.*$", ""),
         site = str_replace(site, "_.*$", "")) %>% 
  distinct(year, site, .keep_all = TRUE) %>% 
  select(-previous_crop)

soil_test    <- read_csv("../data/testing/testing_soil.csv")  %>% 
  mutate(site = str_remove_all(site, "[a-z]"),
         site = str_replace(site, "-.*$", ""),
         site = str_replace(site, "_.*$", ""))

test_base <- submission %>%
  left_join(soil_test, by = c("year","site")) %>%
  left_join(meta_test, by = c("year","site"))

# Downloading Daymet weather for 2024 site‐years 
site_year_test <- test_base %>% 
  select(year, site, lon, lat) %>% 
  distinct()

weather_test <- site_year_test %>%
  mutate(weather = pmap(
    list(.y = year, .site = site, .lat = lat, .lon = lon),
    ~ download_daymet(site = .site,
                      lat   = .lat,
                      lon   = .lon,
                      start = .y,
                      end   = .y,
                      simplify = TRUE,
                      silent = TRUE)
  )) %>%
  select(year, site, weather) %>%
  unnest(weather) %>%
  pivot_wider(names_from = measurement, values_from = value) %>%
  #clean_names()

test_full <- test_base %>%
  left_join(weather_test, by = c("year","site"))

# Feature engineering monthly summaries for 2024 site‐years
fe_test <- test_full %>%
  # creating date & month
  mutate(date = as.Date(paste0(year, "/", yday), "%Y/%j"),
         month_abb = month(date, label = TRUE)) %>%
  # selecting and renaming to match training
  transmute(
    year, site, hybrid,
    month_abb,
    soil.ph       = soilp_h,    # will have to adjust these names if the clean_names() differ
    soil.om.pct   = om_pct,
    soil.k.ppm    = soilk_ppm,
    soil.p.ppm    = soilp_ppm,
    dayl.s        = dayl_s,
    prcp.mm       = prcp_mm_day,
    srad.wm2      = srad_w_m_2,
    tmax.c        = tmax_deg_c,
    tmin.c        = tmin_deg_c,
    vp.pa         = vp_pa
  ) %>%
  group_by(year, site, hybrid, month_abb) %>%
  summarise(
    mean_soil.ph     = mean(soil.ph,   na.rm = TRUE),
    mean_soil.om.pct = mean(soil.om.pct, na.rm = TRUE),
    mean_soil.k.ppm  = mean(soil.k.ppm,  na.rm = TRUE),
    mean_soil.p.ppm  = mean(soil.p.ppm,  na.rm = TRUE),
    mean_dayl.s      = mean(dayl.s,      na.rm = TRUE),
    sum_prcp.mm      = sum(prcp.mm,      na.rm = TRUE),
    mean_srad.wm2    = mean(srad.wm2,    na.rm = TRUE),
    mean_tmax.c      = mean(tmax.c,      na.rm = TRUE),
    mean_tmin.c      = mean(tmin.c,      na.rm = TRUE),
    mean_vp.pa       = mean(vp.pa,       na.omit = TRUE)
  ) %>%
  ungroup() %>%
  pivot_longer(
    cols = starts_with(c("mean_", "sum_")),
    names_to = "name",
    values_to = "value"
  ) %>%
  mutate(varname = paste0(name, "_", month_abb)) %>%
  select(-name, -month_abb) %>%
  pivot_wider(names_from = varname, values_from = value) %>%
  select(-ends_with("_NA"))

# writing into .csv file to directly use in random forest predictions
write_csv(fe_test,
          "../data/testing/testing_submission_fe_test.csv")

# Prepping test features & prediction 
test_prepped  <- bake(weather_prep, new_data = fe_test)

# fitting final model on all training data
final_model   <- final_spec %>% 
  fit(yield ~ ., data = bake(weather_prep, weather))

# generating predictions
predictions   <- predict(final_model, new_data = test_prepped)

# binding back 
submission_pred <- fe_test %>% 
  select(year, site, hybrid) %>% 
  bind_cols(predictions)

write_csv(submission_pred,
          "../data/testing/testing_submission_pred_xgboost.csv")


```

